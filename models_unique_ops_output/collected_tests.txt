STDOUT:
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-6.2.4, py-1.11.0, pluggy-0.13.1 -- /opt/ttforge-toolchain/venv/bin/python
cachedir: .pytest_cache
rootdir: /__w/tt-forge-fe/tt-forge-fe, configfile: pytest.ini
plugins: hydra-core-1.3.2, forked-1.6.0, xdist-2.5.0, timeout-2.0.1, anyio-3.7.1
collecting ... Collecting yolox==0.3.0
  Using cached yolox-0.3.0-cp310-cp310-linux_x86_64.whl
Installing collected packages: yolox
Successfully installed yolox-0.3.0
Automatic Model Analysis Collected tests: 
forge/test/models/pytorch/text/bart/test_bart.py::test_pt_bart_classifier[no_device]
forge/test/models/pytorch/text/distilbert/test_distilbert.py::test_distilbert_masked_lm_pytorch[no_device-distilbert-base-uncased]
forge/test/models/pytorch/text/distilbert/test_distilbert.py::test_distilbert_masked_lm_pytorch[no_device-distilbert-base-cased]
forge/test/models/pytorch/text/distilbert/test_distilbert.py::test_distilbert_masked_lm_pytorch[no_device-distilbert-base-multilingual-cased]
forge/test/models/pytorch/text/distilbert/test_distilbert.py::test_distilbert_question_answering_pytorch[no_device]
forge/test/models/pytorch/text/distilbert/test_distilbert.py::test_distilbert_sequence_classification_pytorch[no_device]
forge/test/models/pytorch/text/distilbert/test_distilbert.py::test_distilbert_token_classification_pytorch[no_device]
forge/test/models/pytorch/vision/autoencoder/test_autoencoder.py::test_conv_ae_pytorch[no_device]
forge/test/models/pytorch/vision/autoencoder/test_autoencoder.py::test_linear_ae_pytorch[no_device]
forge/test/models/pytorch/vision/fpn/test_fpn.py::test_fpn_pytorch[no_device]
Automatic Model Analysis Collected test count: 10
collected 345 items / 335 deselected / 10 selected

<Package bart>
  <Module test_bart.py>
    <Function test_pt_bart_classifier[no_device]>
<Package distilbert>
  <Module test_distilbert.py>
    <Function test_distilbert_masked_lm_pytorch[no_device-distilbert-base-uncased]>
    <Function test_distilbert_masked_lm_pytorch[no_device-distilbert-base-cased]>
    <Function test_distilbert_masked_lm_pytorch[no_device-distilbert-base-multilingual-cased]>
    <Function test_distilbert_question_answering_pytorch[no_device]>
    <Function test_distilbert_sequence_classification_pytorch[no_device]>
    <Function test_distilbert_token_classification_pytorch[no_device]>
<Package autoencoder>
  <Module test_autoencoder.py>
    <Function test_conv_ae_pytorch[no_device]>
    <Function test_linear_ae_pytorch[no_device]>
<Package fpn>
  <Module test_fpn.py>
    <Function test_fpn_pytorch[no_device]>

=============================== warnings summary ===============================
forge/test/models/pytorch/text/bart/test_bart.py:26
  /__w/tt-forge-fe/tt-forge-fe/forge/test/models/pytorch/text/bart/test_bart.py:26: PytestUnknownMarkWarning: Unknown pytest.mark.automatic_model_analysis - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html
    @pytest.mark.automatic_model_analysis

forge/test/models/pytorch/text/distilbert/test_distilbert.py:19
  /__w/tt-forge-fe/tt-forge-fe/forge/test/models/pytorch/text/distilbert/test_distilbert.py:19: PytestUnknownMarkWarning: Unknown pytest.mark.automatic_model_analysis - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html
    @pytest.mark.automatic_model_analysis

forge/test/models/pytorch/text/distilbert/test_distilbert.py:50
  /__w/tt-forge-fe/tt-forge-fe/forge/test/models/pytorch/text/distilbert/test_distilbert.py:50: PytestUnknownMarkWarning: Unknown pytest.mark.automatic_model_analysis - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html
    @pytest.mark.automatic_model_analysis

forge/test/models/pytorch/text/distilbert/test_distilbert.py:87
  /__w/tt-forge-fe/tt-forge-fe/forge/test/models/pytorch/text/distilbert/test_distilbert.py:87: PytestUnknownMarkWarning: Unknown pytest.mark.automatic_model_analysis - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html
    @pytest.mark.automatic_model_analysis

forge/test/models/pytorch/text/distilbert/test_distilbert.py:115
  /__w/tt-forge-fe/tt-forge-fe/forge/test/models/pytorch/text/distilbert/test_distilbert.py:115: PytestUnknownMarkWarning: Unknown pytest.mark.automatic_model_analysis - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html
    @pytest.mark.automatic_model_analysis

../../../opt/ttforge-toolchain/venv/lib/python3.10/site-packages/torchvision/io/image.py:13
  /opt/ttforge-toolchain/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/ttforge-toolchain/venv/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c106detail23torchInternalAssertFailEPKcS2_jS2_RKSs'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
    warn(

forge/test/models/pytorch/vision/autoencoder/test_autoencoder.py:16
  /__w/tt-forge-fe/tt-forge-fe/forge/test/models/pytorch/vision/autoencoder/test_autoencoder.py:16: PytestUnknownMarkWarning: Unknown pytest.mark.automatic_model_analysis - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html
    @pytest.mark.automatic_model_analysis

forge/test/models/pytorch/vision/autoencoder/test_autoencoder.py:44
  /__w/tt-forge-fe/tt-forge-fe/forge/test/models/pytorch/vision/autoencoder/test_autoencoder.py:44: PytestUnknownMarkWarning: Unknown pytest.mark.automatic_model_analysis - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html
    @pytest.mark.automatic_model_analysis

-- Docs: https://docs.pytest.org/en/stable/warnings.html
=============== 10/345 tests collected (335 deselected) in 5.26s ===============
STDERR:
2024-12-02 11:32:58.661602: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2024-12-02 11:32:58.719057: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2024-12-02 11:32:58.719570: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-12-02 11:32:59.632242: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-12-02 11:33:02.707 | DEBUG    | forge.torch_compile:reset_state:50 - Resetting state

  0%|          | 0/1 [00:00<?, ?it/s]
100%|██████████| 1/1 [00:00<00:00, 420.82it/s]
