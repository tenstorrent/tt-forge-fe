# TF & some other libraries report a bunch of deprecation warnings
[pytest]

# Get testcase result
addopts = -v

# Fail on xpassed
xfail_strict=true

# Add pytest markers
markers =
    push: marks tests as push
    nightly: marks tests as nightly
    nightly_sweeps: marks tests as nightly_sweeps
    nightly_models_ops: marks tests as nightly_models_ops
    slow: marks tests as slow               # deprecated - slow tests, should not be run in push pipeline
    run_in_pp: marks tests as run_in_pp     # deprecated - tests that should run in push pipeline
    skip_model_analysis: marks tests as skip_model_analysis

# Where pytest should look for tests
testpaths =
    # Ops
    forge/test/mlir/operators
    forge/test/mlir/test_ops_tf.py
    forge/test/mlir/test_ops_paddle.py
    forge/test/mlir/test_ops_onnx.py
    forge/test/mlir/llama/tests/test_specific_ops_llama32.py

    # Features
    forge/test/mlir/test_features.py

    # Training
    forge/test/mlir/test_loss.py
    forge/test/mlir/test_training.py

    # API
    forge/test/test_api.py

    # Model Tests (PyTorch)
    forge/test/models/pytorch

    # MNIST Linear
    forge/test/mlir/mnist/test_inference.py
    forge/test/mlir/mnist/training/test_training.py

    # Optimizers
    forge/test/mlir/test_optimizers.py

    # Llama
    forge/test/mlir/llama/tests

    # Benchmark
    # MNIST Linear
    forge/test/benchmark/benchmark/models/mnist_linear.py::test_mnist_linear

    # Sweeps
    forge/test/operators/pytorch

    # Models Ops test generated by extracting the unique ops configuration across all the models inside forge/test/models path
    forge/test/models_ops

filterwarnings =
    ignore::DeprecationWarning
