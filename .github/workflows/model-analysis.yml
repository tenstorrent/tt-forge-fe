name: Model Analysis

on:
  workflow_dispatch:
    inputs:
      test_group_cnt:
        description: 'Test group count'
        required: false
        default: "10"
        type: choice
        options:
          - "2"
          - "4"
          - "6"
          - "8"
          - "10"
          - "12"
      runs-on:
        description: 'Runs on'
        required: false
        default: n150
        type: choice
        options:
          - runner
          - wormhole_b0
          - n150
          - n300
          - p150
      tests_to_filter:
        description: 'Filter specific tests (comma-separated): Generate models ops tests only for the specified test commands'
        required: false
        type: string
      ops_to_filter:
        description: 'Filter specific operations (comma-separated): Generate models ops tests only for the specified Forge operations'
        required: false
        type: string
      override_existing_ops:
        description: 'Merge with existing ops: Extract unique ops config from existing models ops tests directory, combine with new filtered tests config, then regenerate all models ops tests'
        required: false
        type: boolean
        default: false
      create_pull_request:
        description: 'Automatically create a Pull Request containing the generated model ops tests.'
        required: false
        type: boolean
        default: false
  # schedule:
  #   - cron: '0 0 * * *'  # Runs at 12:00 UTC every day
  push:
    branches: [ "pchandrasekaran/test_mode_analysis" ]


permissions:
  packages: write
  checks: write

run-name: "Model Analysis (${{inputs.runs-on}}-${{inputs.test_group_cnt}})"

jobs:

  docker-build:
    uses: ./.github/workflows/build-image.yml
    secrets: inherit

  set-inputs:
    runs-on: ubuntu-latest
    needs: docker-build
    if: always()
    outputs:
      test_group_cnt: ${{ steps.set-inputs.outputs.test_group_cnt }}
      test_group_ids: ${{ steps.set-inputs.outputs.test_group_ids }}
      runs-on: ${{ steps.set-inputs.outputs.runs-on }}
      runner: ${{ steps.set-inputs.outputs.runner}}
      create_pr: ${{ steps.set-inputs.outputs.create_pr }}
    steps:
      - name: Inputs Management
        id: set-inputs
        run: |
          default_test_group_cnt=1
          default_runs_on=n150
          default_create_pr=false
          tgc=$(if [ -z "${{ inputs.test_group_cnt }}" ]; then echo $default_test_group_cnt; else echo ${{ inputs.test_group_cnt }}; fi)
          runs_on=$(if [ -z "${{ inputs.runs-on }}" ]; then echo $default_runs_on; else echo ${{ inputs.runs-on}}; fi)
          default_create_pr=$(if [ -z "${{ inputs.create_pull_request }}" ]; then echo $default_create_pr; else echo ${{ inputs.create_pull_request }}; fi)
          echo "test_group_cnt=$tgc" >> $GITHUB_OUTPUT
          echo "test_group_ids=[$(seq -s ',' 1 $tgc)]" >> $GITHUB_OUTPUT
          echo "runs-on=[{\"runs-on\": \"$runs_on\"}]" >> $GITHUB_OUTPUT
          echo "runner=$runs_on" >> $GITHUB_OUTPUT
          echo "create_pr=$default_create_pr" >> $GITHUB_OUTPUT

  build:
    needs:
      - docker-build
      - set-inputs
    uses: ./.github/workflows/build.yml
    secrets: inherit
    with:
      docker-image: ${{ needs.docker-build.outputs.docker-image }}
      build: 'Release'

  extract-unique-ops-configuration:
    needs:
      - docker-build
      - set-inputs
      - build
    uses: ./.github/workflows/test-model-analysis-sub.yml
    secrets: inherit
    with:
      test_mark: 'not (skip_model_analysis or out_of_memory)'
      test_group_cnt: ${{ needs.set-inputs.outputs.test_group_cnt }}
      test_group_ids: ${{ needs.set-inputs.outputs.test_group_ids }}
      docker-image: ${{ needs.docker-build.outputs.docker-image }}
      runs-on: ${{ needs.set-inputs.outputs.runs-on }}
      run_id: ${{ needs.build.outputs.run_id }}
      tests_to_filter: 'forge/test/models/jax/vision/resnet/test_resnet.py::test_resnet[microsoft/resnet-50],forge/test/models/onnx/multimodal/clip/test_clip_onnx.py::test_clip_onnx[openai/clip-vit-base-patch32],forge/test/models/onnx/multimodal/oft/test_oft_onnx.py::test_oft[runwayml/stable-diffusion-v1-5],forge/test/models/onnx/text/albert/test_albert_onnx.py::test_albert_masked_lm_onnx[base-v2],forge/test/models/onnx/text/bert/test_bert.py::test_bert_question_answering_onnx[17-phiyodr/bert-large-finetuned-squad2],forge/test/models/onnx/vision/dla/test_dla.py::test_dla_onnx[dla102x],forge/test/models/onnx/vision/efficientnet/test_efficientnet.py::test_efficientnet_onnx[efficientnet_b5],forge/test/models/onnx/vision/efficientnet/test_efficientnet.py::test_efficientnet_onnx_export_from_package[efficientnet-b3],forge/test/models/onnx/vision/mlp_mixer/test_mlp_mixer_onnx.py::test_mlp_mixer_timm_onnx[mixer_b16_224_miil_in21k],forge/test/models/onnx/vision/monodepth2/test_monodepth2_onnx.py::test_monodepth2[mono_no_pt_640x192],forge/test/models/onnx/vision/perceiverio/test_perceiverio_onnx.py::test_perceiverio_for_image_classification_onnx[deepmind/vision-perceiver-learned],forge/test/models/onnx/vision/regnet/test_regnet_onnx.py::test_regnet_img_classification_onnx[regnet_y_120],forge/test/models/onnx/vision/segformer/test_segformer.py::test_segformer_image_classification_onnx[nvidia/mit-b3],forge/test/models/onnx/vision/segformer/test_segformer.py::test_segformer_image_classification_onnx[nvidia/mit-b4],forge/test/models/onnx/vision/segformer/test_segformer.py::test_segformer_image_classification_onnx[nvidia/mit-b5],forge/test/models/onnx/vision/swin/test_swin.py::test_swin_v2_tiny_masked_onnx[microsoft/swinv2-tiny-patch4-window8-256],forge/test/models/onnx/vision/vgg/test_vgg_onnx.py::test_vgg_osmr_pytorch[vgg16],forge/test/models/onnx/vision/vovnet/test_vovnet.py::test_vovnet_osmr_pytorch[vovnet27s],forge/test/models/onnx/vision/vovnet/test_vovnet.py::test_vovnet_v1_57_stigma_onnx[vovnet_v1_57],forge/test/models/onnx/vision/yolo/test_yolo_v5_onnx.py::test_yolov5_320x320[yolov5s],forge/test/models/onnx/vision/yolo/test_yolox_onnx.py::test_yolox_pytorch[yolox_x],forge/test/models/paddlepaddle/multimodal/blip/test_blip.py::test_blip[Salesforce/blip-image-captioning-base],forge/test/models/paddlepaddle/multimodal/clip/test_chineseclip.py::test_chineseclip[OFA-Sys/chinese-clip-vit-base-patch16],forge/test/models/paddlepaddle/multimodal/paddleocr/test_paddleocr_rec.py::test_paddleocr_rec[v0_rec_en-https://paddleocr.bj.bcebos.com/dygraph_v2.0/multilingual/en_number_mobile_v2.0_rec_infer.tar],forge/test/models/paddlepaddle/text/t5/test_t5.py::test_t5_conditional_generation[t5-small],forge/test/models/paddlepaddle/vision/mobilenet/test_mobilenet_v1.py::test_mobilenetv1_basic,forge/test/models/pytorch/audio/whisper/test_whisper.py::test_whisper[openai/whisper-tiny],forge/test/models/pytorch/multimodal/llama3/test_llama3_pt.py::test_llama_vision_Instruct[meta-llama/Llama-3.2-90B-Vision-Instruct],forge/test/models/pytorch/multimodal/vilt/test_vilt.py::test_vilt_question_answering_hf_pytorch[vqa],forge/test/models/pytorch/text/albert/test_albert.py::test_albert_masked_lm_pytorch[xlarge_v1],forge/test/models/pytorch/text/albert/test_albert.py::test_albert_token_classification_pytorch[xlarge_v2],forge/test/models/pytorch/text/bert/test_bert.py::test_bert_sequence_classification_pytorch[textattack/bert-base-uncased-SST-2],forge/test/models/pytorch/text/distilbert/test_distilbert.py::test_distilbert_question_answering_pytorch[distilbert-base-cased-distilled-squad],forge/test/models/pytorch/text/dpr/test_dpr.py::test_dpr_reader_pytorch[facebook/dpr-reader-multiset-base],forge/test/models/pytorch/text/flux/test_flux.py::test_flux[black-forest-labs/FLUX.1-schnell],forge/test/models/pytorch/text/gpt2/test_gpt2.py::test_gpt2_variants[gpt2_sequence_classification],forge/test/models/pytorch/text/llama/test_llama3.py::test_llama3_sequence_classification_pytorch[llama_3_2_1b_instruct],forge/test/models/pytorch/text/phi1/test_phi1.py::test_phi1_causal_lm_pytorch[microsoft/phi-1],forge/test/models/pytorch/text/qwen/test_qwen_v2_5.py::test_qwen2_conditional_generation[Qwen/QVQ-72B-Preview],forge/test/models/pytorch/text/qwen/test_qwen_v2_5_coder.py::test_qwen_coder_clm_pytorch[0_5b],forge/test/models/pytorch/text/roberta/test_roberta.py::test_roberta_masked_lm[xlm_base],forge/test/models/pytorch/text/solar/test_solar.py::test_solar[upstage/SOLAR-10.7B-Instruct-v1.0],forge/test/models/pytorch/text/xglm/test_xglm.py::test_xglm_causal_lm[xglm-564M],forge/test/models/pytorch/vision/densenet/test_densenet.py::test_densenet_pytorch[densenet121],forge/test/models/pytorch/vision/dla/test_dla.py::test_dla_pytorch[dla60],forge/test/models/pytorch/vision/dla/test_dla.py::test_dla_pytorch[dla60x_c],forge/test/models/pytorch/vision/efficientnet/test_efficientnet.py::test_efficientnet_timm[efficientnet_b4],forge/test/models/pytorch/vision/efficientnet/test_efficientnet.py::test_efficientnet_timm[hf_hub_timm_efficientnetv2_rw_s_ra2_in1k],forge/test/models/pytorch/vision/efficientnet/test_efficientnet.py::test_efficientnet_torchvision[efficientnet_b0],forge/test/models/pytorch/vision/efficientnet/test_efficientnet_lite.py::test_efficientnet_lite_timm[tf_efficientnet_lite3.in1k],forge/test/models/pytorch/vision/hrnet/test_hrnet.py::test_hrnet_osmr_pytorch[hrnetv2_w40_osmr],forge/test/models/pytorch/vision/hrnet/test_hrnet.py::test_hrnet_timm_pytorch[hrnet_w32],forge/test/models/pytorch/vision/hrnet/test_hrnet.py::test_hrnet_timm_pytorch[hrnet_w40],forge/test/models/pytorch/vision/hrnet/test_hrnet.py::test_hrnet_timm_pytorch[hrnet_w44],forge/test/models/pytorch/vision/hrnet/test_hrnet.py::test_hrnet_timm_pytorch[hrnet_w48],forge/test/models/pytorch/vision/hrnet/test_hrnet.py::test_hrnet_timm_pytorch[hrnet_w64],forge/test/models/pytorch/vision/hrnet/test_hrnet.py::test_hrnet_timm_pytorch[hrnet_w18.ms_aug_in1k],forge/test/models/pytorch/vision/mlp_mixer/test_mlp_mixer.py::test_mlp_mixer_timm_pytorch[mixer_s32_224],forge/test/models/pytorch/vision/mobilenet/test_mobilenet_v2.py::test_mobilenetv2_basic[mobilenet_v2],forge/test/models/pytorch/vision/mobilenet/test_mobilenet_v3.py::test_mobilenetv3_timm[mobilenetv3_large_100],forge/test/models/pytorch/vision/monodepth2/test_monodepth2.py::test_monodepth2[mono_no_pt_640x192],forge/test/models/pytorch/vision/monodle/test_monodle.py::test_monodle_pytorch,forge/test/models/pytorch/vision/oft/test_oft.py::test_oft,forge/test/models/pytorch/vision/perceiverio/test_perceiverio.py::test_perceiverio_for_image_classification_pytorch[deepmind/vision-perceiver-fourier],forge/test/models/pytorch/vision/regnet/test_regnet.py::test_regnet_torchvision[regnet_y_16gf],forge/test/models/pytorch/vision/regnet/test_regnet.py::test_regnet_torchvision[regnet_x_800mf],forge/test/models/pytorch/vision/resnext/test_resnext.py::test_resnext_osmr_pytorch[resnext26_32x4d_osmr],forge/test/models/pytorch/vision/segformer/test_segformer.py::test_segformer_semantic_segmentation_pytorch[b3_finetuned_ade_512_512],forge/test/models/pytorch/vision/suryaocr/test_surya_ocr_text.py::test_surya_ocr,forge/test/models/pytorch/vision/swin/test_swin.py::test_swin_torchvision[swin_t],forge/test/models/pytorch/vision/vgg/test_vgg.py::test_vgg_osmr_pytorch[vgg11],forge/test/models/pytorch/vision/yolo/test_yolo_v4.py::test_yolo_v4,forge/test/models/pytorch/vision/yolo/test_yolo_v5.py::test_yolov5_320x320[yolov5s],forge/test/models/pytorch/vision/yolo/test_yolo_v5.py::test_yolov5_640x640[yolov5n],forge/test/models/pytorch/vision/yolo/test_yolo_v5.py::test_yolov5_640x640[yolov5x],forge/test/models/tensorflow/vision/resnet/test_resnet.py::test_resnet_tensorflow'
      allow-fail: true

  generate-models-ops-tests:

    needs:
      - docker-build
      - set-inputs
      - build
      - extract-unique-ops-configuration

    runs-on: ["in-service", "${{ needs.set-inputs.outputs.runner }}" ]

    container:
      image: ${{ needs.docker-build.outputs.docker-image }}
      options: --device /dev/tenstorrent/0
      volumes:
        - /dev/hugepages:/dev/hugepages
        - /dev/hugepages-1G:/dev/hugepages-1G
        - /etc/udev/rules.d:/etc/udev/rules.d
        - /lib/modules:/lib/modules
        - /opt/tt_metal_infra/provisioning/provisioning_env:/opt/tt_metal_infra/provisioning/provisioning_env
        - /mnt/dockercache:/mnt/dockercache

    steps:

      - name: Set reusable strings
        id: strings
        shell: bash
        run: |
          echo "work-dir=$(pwd)" >> "$GITHUB_OUTPUT"
          echo "build-output-dir=$(pwd)/build" >> "$GITHUB_OUTPUT"

      - name: Git safe dir
        run: git config --global --add safe.directory ${{ steps.strings.outputs.work-dir }}

      - uses: actions/checkout@v4
        with:
            submodules: recursive
            fetch-depth: 0 # Fetch all history and tags
            token: ${{ secrets.GH_TOKEN }}

      # Clean everything from submodules (needed to avoid issues
      # with cmake generated files leftover from previous builds)
      - name: Cleanup submodules
        run: |
            git submodule foreach --recursive git clean -ffdx
            git submodule foreach --recursive git reset --hard

      - name: Set environment variables
        shell: bash
        run: |
            OUTPUT=$(bash .github/model-analysis-config.sh)
            # Assign the script output to GitHub environment variables
            echo "$OUTPUT" | while IFS= read -r line; do
              echo "$line" >> $GITHUB_ENV
            done

      - name: Download all Models Unique Ops Config artifacts
        shell: bash
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          bash .github/download-model-analysis-artifacts.sh "${{ github.repository }}" "${{ github.run_id }}" "${{ env.UNIQUE_OPS_OUTPUT_DIR_PATH }}"

      - name: Download wheel
        if: ${{ needs.build.outputs.run_id }}
        continue-on-error: true
        uses: tenstorrent/tt-forge/.github/actions/download-artifact@main
        with:
          name: forge-wheel
          run_id: ${{ needs.build.outputs.run_id }}
          github_token: ${{ secrets.GITHUB_TOKEN }}

      - name: Install wheel
        shell: bash
        run: |
          source env/activate
          pip install tt_tvm*.whl --force-reinstall
          pip install tt_forge_fe*.whl --force-reinstall

      - name: Generate Models Ops tests
        shell: bash
        run: |
          source env/activate
          set -o pipefail # Ensures that the exit code reflects the first command that fails

          command_args=(
            "--extracted_unique_ops_config_directory_path" "${{ env.UNIQUE_OPS_OUTPUT_DIR_PATH }}"
            "--models_ops_test_output_directory_path" "${{ env.MODELS_OPS_TEST_OUTPUT_DIR_PATH }}"
            "--models_ops_test_package_name" "${{ env.MODELS_OPS_TEST_PACKAGE_NAME }}"
          )

          if [ -n "${{ inputs.ops_to_filter }}" ]; then
            # Split on commas and trim whitespace
            IFS=',' read -r -a ops_filters <<< "${{ inputs.ops_to_filter }}"
            command_args+=("--ops_to_filter")
            for of in "${ops_filters[@]}"; do
              command_args+=("$(echo "$of" | xargs)")
            done
          fi

          if [[ "${{ inputs.override_existing_ops }}" == "true" && -n "${{ inputs.tests_to_filter }}" ]]; then
            command_args+=("--override_existing_ops")
          fi

          python scripts/model_analysis/combine_and_generate_ops_tests.py "${command_args[@]}" \
            2>&1 | tee ${{ env.SCRIPT_OUTPUT_LOG }}

      - name: Upload Script Output Logs
        uses: actions/upload-artifact@v4
        if: success() || failure()
        with:
          name: script-outputs
          path: ${{ env.SCRIPT_OUTPUT_LOG }}

      - name: Upload Models Unique Ops Output
        uses: actions/upload-artifact@v4
        if: success() || failure()
        with:
          name: models-unique-ops-output
          path: ${{ env.UNIQUE_OPS_OUTPUT_DIR_PATH }}

      - name: Upload Generated Models Ops Tests
        uses: actions/upload-artifact@v4
        if: ${{ needs.set-inputs.outputs.create_pr == 'false' }}
        with:
          name: generated-models-ops-tests
          path: ${{ env.GENERATED_MODELS_OPS_TESTS_PATH }}

      - name: Create Pull Request
        uses: peter-evans/create-pull-request@v7
        if: ${{ needs.set-inputs.outputs.create_pr == 'true' }}
        with:
          branch: ${{ env.BRANCH_NAME }}
          committer: github-actions[bot] <41898282+github-actions[bot]@users.noreply.github.com>
          author: ${{ github.actor }} <${{ github.actor }}@users.noreply.github.com>
          base: main
          commit-message: ${{ env.COMMIT_MESSAGE }}
          title: ${{ env.TITLE }}
          body: ${{ env.BODY }}
          delete-branch: true
          token: ${{ secrets.GH_TOKEN }}
          add-paths: |
              ${{ env.GENERATED_MODELS_OPS_TESTS_PATH }}

  run-models-ops-tests:
    if: ${{ needs.set-inputs.outputs.create_pr == 'false' }}
    needs:
      - docker-build
      - set-inputs
      - build
      - extract-unique-ops-configuration
      - generate-models-ops-tests
    uses: ./.github/workflows/test-sub.yml
    secrets: inherit
    with:
      docker-image: ${{ needs.docker-build.outputs.docker-image }}
      test_mark: 'nightly_models_ops'
      test_group_cnt: ${{ needs.set-inputs.outputs.test_group_cnt }}
      test_group_ids: ${{ needs.set-inputs.outputs.test_group_ids }}
      runs-on: '[{"runs-on": "n150"}]'
      sh-runner: true
      run_id: ${{ needs.build.outputs.run_id }}
      run_models_ops_tests: true
      test-expression: 'inference'
      allow-fail: true
