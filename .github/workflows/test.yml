name: Test

on:
  workflow_call:
    inputs:
      test_mark:
        description: 'Test mark to run'
        required: false
        default: 'push'
        type: string
      test_group_cnt:
        description: 'Test group count'
        required: false
        default: 2
        type: number
      test_group_ids:
        description: 'Test group ids'
        required: false
        default: '[1,2]'
        type: string
      docker-image:
        description: 'Docker image to use for build'
        required: true
        type: string
      runs-on:
        description: 'Runs on'
        required: false
        type: string
        default: '[{"runs-on": "n150"}, {"runs-on": "n300"}]'
      operators:
        description: 'Operators to test (comma separated)'
        required: false
        type: string
      on_nightly_run_id:
        description: 'Run ID for the on-nightly workflow used to generate the WHL installer'
        required: false
        type: string

permissions:
  packages: write
  checks: write
  pull-requests: write # only required if `comment: true` was enabled

jobs:

  run-tests:

    strategy:
      fail-fast: false
      matrix:
        build: ${{ fromJson(inputs.runs-on) }}
        test_group_id: ${{ fromJson(inputs.test_group_ids) }}

    runs-on:
      - in-service
      - ${{ matrix.build.runs-on }}

    container:
      image: ${{ inputs.docker-image }}
      options: --device /dev/tenstorrent/0
      volumes:
        - /dev/hugepages:/dev/hugepages
        - /dev/hugepages-1G:/dev/hugepages-1G
        - /etc/udev/rules.d:/etc/udev/rules.d
        - /lib/modules:/lib/modules
        - /opt/tt_metal_infra/provisioning/provisioning_env:/opt/tt_metal_infra/provisioning/provisioning_env
        - /mnt/dockercache:/mnt/dockercache

    name: "run-tests ${{ inputs.test_mark }} (${{ matrix.build.runs-on }}, ${{ matrix.test_group_id }})"
    steps:

    - name: Fetch job id
      id: fetch-job-id
      uses: tenstorrent/tt-github-actions/.github/actions/job_id@main
      with:
        job_name: "run-tests ${{ inputs.test_mark }} (${{ matrix.build.runs-on }}, ${{ matrix.test_group_id }})"

    - name: Set reusable strings
      id: strings
      shell: bash
      env:
        JOB_ID: ${{ steps.fetch-job-id.outputs.job_id }}
      run: |
        echo "work-dir=$(pwd)" >> "$GITHUB_OUTPUT"
        echo "build-output-dir=$(pwd)/build" >> "$GITHUB_OUTPUT"
        echo "test_report_path=reports/report_$JOB_ID.xml" >> "$GITHUB_OUTPUT"

    - name: Git safe dir
      run: git config --global --add safe.directory ${{ steps.strings.outputs.work-dir }}

    - uses: actions/checkout@v4
      with:
          sparse-checkout: |
            env/
            forge/test
            pytest.ini
            conftest.py
            .test_durations

    # Clean everything from submodules (needed to avoid issues
    # with cmake generated files leftover from previous builds)
    - name: Cleanup submodules
      run: |
          git submodule foreach --recursive git clean -ffdx
          git submodule foreach --recursive git reset --hard

    - name: Download wheel
      uses: actions/download-artifact@v4
      with:
        name: forge-wheel
        # Prioritize input run ID, if not available use current run (for new builds)
        run-id: ${{ inputs.on_nightly_run_id || github.run_id }}
        github-token: ${{ github.token }}

    - name: Install wheel
      shell: bash
      run: |
        source env/activate
        pip install tvm*.whl --force-reinstall
        pip install forge*.whl --force-reinstall

    - name: Run Test
      env:
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
        HF_HOME: /mnt/dockercache/huggingface
        HF_HUB_DISABLE_PROGRESS_BARS: 1
        FORGE_DISABLE_REPORTIFY_DUMP: 1
        OPERATORS: ${{ inputs.operators }}
      shell: bash
      run: |
        source env/activate
        pytest --splits ${{ inputs.test_group_cnt }} \
               --group ${{ matrix.test_group_id }} \
               --splitting-algorithm least_duration \
               -m "${{ inputs.test_mark }}" \
               --junit-xml=${{ steps.strings.outputs.test_report_path }}

    - name: Upload Test Report
      uses: actions/upload-artifact@v4
      if: success() || failure()
      with:
        name: test-reports-${{ matrix.build.runs-on }}-${{ matrix.test_group_id }}-${{ steps.fetch-job-id.outputs.job_id }}
        path: ${{ steps.strings.outputs.test_report_path }}

    - name: Show Test Report
      uses: mikepenz/action-junit-report@v5
      if: success() || failure()
      with:
        report_paths: ${{ steps.strings.outputs.test_report_path }}
        check_name: TT-Forge-FE Tests
        comment: true
        updateComment: false
        detailed_summary: true
        group_suite: true
